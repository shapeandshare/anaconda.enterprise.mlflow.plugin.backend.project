{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Hyper Parameter Tuning with MLFlow\n",
    "\n",
    "Adapted from https://github.com/mlflow/mlflow/tree/master/examples/hyperparam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up runtime environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "from anaconda.enterprise.server.common.sdk import load_ae5_user_secrets\n",
    "\n",
    "logging.getLogger().setLevel(logging.DEBUG)\n",
    "\n",
    "load_ae5_user_secrets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define our parameter search space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from hyperopt import hp\n",
    "\n",
    "# Define the search space\n",
    "# https://hyperopt.github.io/hyperopt/\n",
    "space = [\n",
    "    hp.uniform(\"lr\", 1e-5, 1e-1),\n",
    "    hp.uniform(\"momentum\", 0.0, 1.0),\n",
    "]\n",
    "\n",
    "_inf = np.finfo(np.float64).max\n",
    "seed: int = 97531"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an MLFlow client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "# Generate a client\n",
    "tracking_client = MlflowClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define our best run search (report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def get_best_run(experiment_id, run):\n",
    "    # find the best run, log its metrics as the final metrics of this run.\n",
    "    runs = tracking_client.search_runs(\n",
    "        [experiment_id], \"tags.mlflow.parentRunId = '{run_id}' \".format(run_id=run.info.run_id)\n",
    "    )\n",
    "    best_val_train = _inf\n",
    "    best_val_valid = _inf\n",
    "    best_val_test = _inf\n",
    "    best_run = None\n",
    "    for r in runs:\n",
    "        if r.data.metrics[\"val_rmse\"] < best_val_valid:\n",
    "            best_run = r\n",
    "            best_val_train = r.data.metrics[\"train_rmse\"]\n",
    "            best_val_valid = r.data.metrics[\"val_rmse\"]\n",
    "            best_val_test = r.data.metrics[\"test_rmse\"]\n",
    "    return best_run, best_val_train, best_val_valid, best_val_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Training (with paramertization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "\n",
    "def parameterized_training(nepochs, lr, momentum, experiment_id, training_data):\n",
    "    with mlflow.start_run(run_name=f\"parameterized-training-{str(uuid.uuid4())}\", nested=True) as child_run:\n",
    "        #\n",
    "        # Wrapped and Tracked Workflow Step Runs\n",
    "        # https://mlflow.org/docs/latest/python_api/mlflow.projects.html#mlflow.projects.run\n",
    "        #\n",
    "        p = mlflow.projects.run(\n",
    "            uri=\".\",\n",
    "            entry_point=\"train\",\n",
    "            run_id=child_run.info.run_id,\n",
    "            env_manager=\"local\",\n",
    "            backend=\"adsp\",\n",
    "            parameters={\n",
    "                \"training_data\": training_data,\n",
    "                \"epochs\": str(nepochs),\n",
    "                \"learning_rate\": str(lr),\n",
    "                \"momentum\": str(momentum),\n",
    "                \"seed\": seed,\n",
    "            },\n",
    "            experiment_id=experiment_id,\n",
    "            synchronous=False,  # Allow the run to fail if a model is not properly created\n",
    "        )\n",
    "        succeeded = p.wait()\n",
    "        mlflow.log_params({\"lr\": lr, \"momentum\": momentum})\n",
    "\n",
    "    return succeeded, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import mlflow.tracking\n",
    "\n",
    "\n",
    "def new_eval(\n",
    "    nepochs,\n",
    "    experiment_id,\n",
    "    null_train_loss,\n",
    "    null_valid_loss,\n",
    "    null_test_loss,\n",
    "    training_data,\n",
    "    return_all=False,\n",
    "    metric=\"rmse\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Create a new eval function\n",
    "\n",
    "    :param nepochs: Number of epochs to train the model.\n",
    "    :experiment_id: Experiment id for the training run\n",
    "    :valid_null_loss: Loss of a null model on the validation dataset\n",
    "    :test_null_loss: Loss of a null model on the test dataset.\n",
    "    :return_test_loss: Return both validation and test loss if set.\n",
    "\n",
    "    :return: new eval function.\n",
    "    \"\"\"\n",
    "\n",
    "    def eval(params):\n",
    "        \"\"\"\n",
    "        Train Keras model with given parameters by invoking MLflow run.\n",
    "\n",
    "        Notice we store runUuid and resulting metric in a file. We will later use these to pick\n",
    "        the best run and to log the runUuids of the child runs as an artifact. This is a\n",
    "        temporary workaround until MLflow offers better mechanism of linking runs together.\n",
    "\n",
    "        :param params: Parameters to the train_keras script we optimize over:\n",
    "                      learning_rate, drop_out_1\n",
    "        :return: The metric value evaluated on the validation data.\n",
    "        \"\"\"\n",
    "\n",
    "        lr, momentum = params\n",
    "        succeeded, p = parameterized_training(\n",
    "            nepochs=nepochs, experiment_id=experiment_id, lr=lr, momentum=momentum, training_data=training_data\n",
    "        )\n",
    "\n",
    "        if succeeded:\n",
    "            training_run = tracking_client.get_run(p.run_id)\n",
    "            metrics = training_run.data.metrics\n",
    "            # cap the loss at the loss of the null model\n",
    "            train_loss = min(null_train_loss, metrics[\"train_{}\".format(metric)])\n",
    "            valid_loss = min(null_valid_loss, metrics[\"val_{}\".format(metric)])\n",
    "            test_loss = min(null_test_loss, metrics[\"test_{}\".format(metric)])\n",
    "        else:\n",
    "            # run failed => return null loss\n",
    "            tracking_client.set_terminated(p.run_id, \"FAILED\")\n",
    "            train_loss = null_train_loss\n",
    "            valid_loss = null_valid_loss\n",
    "            test_loss = null_test_loss\n",
    "\n",
    "        # Log this tuning runs metrics\n",
    "        mlflow.log_metrics(\n",
    "            {\n",
    "                \"train_{}\".format(metric): train_loss,\n",
    "                \"val_{}\".format(metric): valid_loss,\n",
    "                \"test_{}\".format(metric): test_loss,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        if return_all:\n",
    "            return train_loss, valid_loss, test_loss\n",
    "        else:\n",
    "            return valid_loss\n",
    "\n",
    "    return eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from hyperopt import fmin, tpe, rand\n",
    "import mlflow\n",
    "\n",
    "\n",
    "def tune(max_runs, epochs, training_data, metric=\"rmse\", algo=\"tpe.suggest\"):\n",
    "    \"\"\"Run hyperparameter optimization.\"\"\"\n",
    "\n",
    "    with mlflow.start_run(run_name=f\"hyperparamter-optimization-jburt-{str(uuid.uuid4())}\") as run:\n",
    "        experiment_id = run.info.experiment_id\n",
    "\n",
    "        # Evaluate null model first.\n",
    "        train_null_loss, valid_null_loss, test_null_loss = new_eval(\n",
    "            0, experiment_id, _inf, _inf, _inf, training_data, True, metric\n",
    "        )(params=[0, 0])\n",
    "\n",
    "        # perform parameter search\n",
    "        best = fmin(\n",
    "            fn=new_eval(\n",
    "                epochs,\n",
    "                experiment_id,\n",
    "                train_null_loss,\n",
    "                valid_null_loss,\n",
    "                test_null_loss,\n",
    "                training_data=training_data,\n",
    "                metric=metric,\n",
    "            ),\n",
    "            space=space,\n",
    "            algo=tpe.suggest if algo == \"tpe.suggest\" else rand.suggest,\n",
    "            max_evals=max_runs,\n",
    "        )\n",
    "        # log the best parameters\n",
    "        mlflow.set_tag(\"best params\", str(best))\n",
    "\n",
    "        # find the best run, log its metrics as the final metrics of this run.\n",
    "        best_run, best_val_train, best_val_valid, best_val_test = get_best_run(experiment_id, run)\n",
    "\n",
    "        # Tag final metrics\n",
    "        mlflow.set_tag(\"best_run\", best_run.info.run_id)\n",
    "        mlflow.log_metrics(\n",
    "            {\n",
    "                \"train_{}\".format(metric): best_val_train,\n",
    "                \"val_{}\".format(metric): best_val_valid,\n",
    "                \"test_{}\".format(metric): best_val_test,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"best\": {\"params\": str(best), \"run\": best_run.info.run_id},\n",
    "            \"metrics\": {\n",
    "                \"train_{}\".format(metric): best_val_train,\n",
    "                \"val_{}\".format(metric): best_val_valid,\n",
    "                \"test_{}\".format(metric): best_val_test,\n",
    "            },\n",
    "            \"details\": {\"experiment_id\": experiment_id, \"max_runs\": max_runs, \"epochs\": epochs},\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform the Parameter Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Data Source\n",
    "# http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv\n",
    "\n",
    "summary = tune(max_runs=3, epochs=16, training_data=\"data/winequality-white.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "print(json.dumps(summary, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) [default]",
   "language": "python",
   "name": "anaconda-project-default-python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
